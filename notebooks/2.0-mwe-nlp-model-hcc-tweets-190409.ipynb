{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk \n",
    "import sklearn\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sqlite3 import Error\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.naive_bayes.BernoulliNB import BernoulliNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweet_id', 'created_at', 'tweet', 'relevant to liver disease/cancer',\n",
       "       'anecdote/experiential',\n",
       "       'cites academic study or credible organization or doctor',\n",
       "       'claim about liver cancer cure/cause', 'truth of claim',\n",
       "       'contains link', 'retweet', 'in_reply_to_status_id',\n",
       "       'in_reply_to_user_id', 'in_reply_to_screen_name', 'geo',\n",
       "       'retweet_count', 'favorite_count', 'favorited', 'retweeted', 'user_id',\n",
       "       'username', 'screen_name', 'user_location', 'user_description',\n",
       "       'user_url', 'followers_count', 'friends_count', 'listed_count',\n",
       "       'user_favorites_count', 'statuses_count', 'user_lang', 'location',\n",
       "       'place'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel('../data/database/hcc_tweets_train_label.xlsx')\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and test sets\n",
    "X = data['tweet']\n",
    "X.dropna(inplace=True)\n",
    "y = data['relevant to liver disease/cancer']\n",
    "y = y[:2009]\n",
    "y.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: tweet, dtype: object)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for non-string values\n",
    "X[X.apply(lambda x: type(x)) != str]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rt @undarkmag: the esophag line canâ€™t toler repeat exposur stomach acid begin change, cell cell. divisionâ€¦'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def preprocess_text(row, stemmer, stopwords):\n",
    "    row = row.split()\n",
    "    result = [stemmer.stem(word) for word in row if word not in stopwords]\n",
    "    result = ' '.join(result).lower() # Convert to lowercase string\n",
    "    return result\n",
    "\n",
    "preprocess_text(X[0], stemmer, words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       rt @undarkmag: the esophag line canâ€™t toler re...\n",
       "1       rt @lqstrengthcoach: pleas keep mom prayers. h...\n",
       "2       et1402l1-artemisâ„¢2 t cell afp express hepatoce...\n",
       "3       rt @earthjustice: each day chemic permit job e...\n",
       "4       doe aspirin reduc risk liver cancer patient ch...\n",
       "5       @cash__9 becaus liver made hepatocyt cell endo...\n",
       "6       rt @earthjustice: each day chemic permit job e...\n",
       "7       eat more okra: it help control diabetes, rever...\n",
       "8       @buffa82 cancer suck indeed. lost dear friend ...\n",
       "9       @theellenshow @cheerio 2 2 abd addit want live...\n",
       "10      eat more okra: it help control diabetes, rever...\n",
       "11      rt @jennycohn1: 2/ example: \"a studi done show...\n",
       "12      *sighs* so liver level high could xome oral ch...\n",
       "13      rt @dr_novchinsky: honor present behalf americ...\n",
       "14      a video new invention, 20 twentea:cancer, diab...\n",
       "15      my stepfath put hospice. he liver cancer stage...\n",
       "16      rt @essonews: @essonew support 13th intern liv...\n",
       "17      have ever seen someon liver cancer hepatitis? ...\n",
       "18      my patient today walk look fire bomb outfit he...\n",
       "19      @kevin93527144 @caillin_justic @berniesand whe...\n",
       "20      rt @exelixisinc: rare diseas affect 300 millio...\n",
       "21      world' healthiest vegetable: it can restor you...\n",
       "22      today i put dog ðŸ˜­ cancer spleen liver. we put ...\n",
       "23      rt @earthjustice: each day chemic permit job e...\n",
       "24      rt @p1nky2010: @mainstreethfx @nightshiftmd my...\n",
       "25      rt @organiclivefood: eat #avocado help ur #liv...\n",
       "26      awesom report daniel portergardner! kkeep pray...\n",
       "27      rt @johnjfioregolf: pleas help @johnjfioregolf...\n",
       "28      rt @earthjustice: each day chemic permit job e...\n",
       "29      @nankleff48 she die hospic liver cancer. i dou...\n",
       "                              ...                        \n",
       "1979    yeah patrick s. had like liver cancer https://...\n",
       "1980    16 tobacco-link cancers: lung cancer cancer mo...\n",
       "1981    rt @dcpoll: @daveamerika no, i'm realli dumb a...\n",
       "1982    @lynndiwagon i sorri - girl diagnos liver canc...\n",
       "1983    rt @dcpoll: @daveamerika no, i'm realli dumb a...\n",
       "1984    rt @thenci: research found unconvent way unlea...\n",
       "1985    rt @thesopranosclub: rememb actress denis bori...\n",
       "1986                        @zboii17 liver cancer, i come\n",
       "1987    liver cancer surviv rate https://t.co/tyvf1rlz...\n",
       "1988    @sirfreebie75061 yes, die liver cancer hodgkin...\n",
       "1989    @beneaththedirt yeah third time two week :/ la...\n",
       "1990    will take two tomato day keep doctor away? @jm...\n",
       "1991    last brain exam left pituitari tumor,.. liver ...\n",
       "1992    rt @beatthemedian: just wonder secondari breas...\n",
       "1993    rt @beatthemedian: just wonder secondari breas...\n",
       "1994    rt @lynndiwagon: blossom pass away today liver...\n",
       "1995    @gerrycardinal cigarett caus cancer, alcohol c...\n",
       "1996    just wonder secondari breast cancer patient y9...\n",
       "1997    @mdandersonnew @cancerfrontlin my oldest frien...\n",
       "1998    rt @radiology_ai: autom segment colorect cance...\n",
       "1999    @karoli way make difficult peopl pain. my frie...\n",
       "2000    rt @hccconnectinfo: five hcc connect member au...\n",
       "2001    .@melaniatrump pretenti &amp; vacuous feign #b...\n",
       "2002    rt @hccconnectinfo: five hcc connect member au...\n",
       "2003    @realdonaldtrump .@melaniatrump pretenti &amp;...\n",
       "2004                              https://t.co/kac8q4m8nv\n",
       "2005    rt @hccconnectinfo: five hcc connect member au...\n",
       "2006    rt @hccconnectinfo: five hcc connect member au...\n",
       "2007    five hcc connect member author review paper â€˜s...\n",
       "2008    rt @ipanditaiin: accord pakistan maulana masoo...\n",
       "Name: tweet, Length: 2009, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "words = stopwords.words(\"english\")\n",
    "\n",
    "X = X.apply(lambda x: preprocess_text(x, stemmer, words))\n",
    "X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2009, 3089)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(min_df= 3, stop_words=\"english\", sublinear_tf=True, norm='l2', ngram_range=(1, 2))\n",
    "final_features = vectorizer.fit_transform(X).toarray()\n",
    "final_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.98      0.97       415\n",
      "         1.0       0.89      0.83      0.86        88\n",
      "\n",
      "   micro avg       0.95      0.95      0.95       503\n",
      "   macro avg       0.93      0.90      0.92       503\n",
      "weighted avg       0.95      0.95      0.95       503\n",
      "\n",
      "[[406   9]\n",
      " [ 15  73]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mattheweng/anaconda/envs/med-fact/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.25)\n",
    "\n",
    "# instead of doing these steps one at a time, we can use a pipeline to complete them all at once\n",
    "pipeline = Pipeline([('vect', vectorizer),\n",
    "                     ('chi',  SelectKBest(chi2, k=1200)),\n",
    "                     ('clf', RandomForestClassifier())])\n",
    "\n",
    "# fitting our model and save it in a pickle for later use\n",
    "model = pipeline.fit(X_train, y_train)\n",
    "# with open('RandomForest.pickle', 'wb') as f:\n",
    "#     pickle.dump(model, f)\n",
    "ytest = np.array(y_test)\n",
    "\n",
    "# confusion matrix and classification report(precision, recall, F1-score)\n",
    "print(classification_report(ytest, model.predict(X_test)))\n",
    "print(confusion_matrix(ytest, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Identify features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (medfact)",
   "language": "python",
   "name": "med-fact"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
